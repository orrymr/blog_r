<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inverse on orrymr.com</title>
    <link>/tags/inverse/</link>
    <description>Recent content in Inverse on orrymr.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 18 Nov 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/inverse/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Inverse Matrices - A Primer</title>
      <link>/post/inverse-matrix/</link>
      <pubDate>Sun, 18 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/inverse-matrix/</guid>
      <description>

&lt;h1 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h1&gt;

&lt;p&gt;In this post &lt;strong&gt;we talk about the&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;inverse matrix&lt;/em&gt;&lt;/strong&gt;. We discuss what it means for a matrix to be &lt;em&gt;invertible&lt;/em&gt;. We then discuss what it means for a matrix &lt;em&gt;not&lt;/em&gt; to be invertible - &lt;em&gt;singular&lt;/em&gt;. Finally, we briefly go through how to find a matrix&amp;rsquo;s inverse.&lt;/p&gt;

&lt;h1 id=&#34;2-invertibility&#34;&gt;2. Invertibility&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s think about a square matrix, &lt;code&gt;$A$&lt;/code&gt;. In &lt;a href=&#34;/post/second-post/&#34;&gt;a previous post&lt;/a&gt; we mentioned that &lt;strong&gt;a matrix acts on a vector&lt;/strong&gt;. The matrix does something to that vector.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The inverse of a matrix undoes what the original matrix did.&lt;/strong&gt; The inverse of &lt;code&gt;$A$&lt;/code&gt; is &lt;code&gt;$A^{-1}$&lt;/code&gt;. &lt;code&gt;$A^{-1}$&lt;/code&gt; undoes what &lt;code&gt;$A$&lt;/code&gt; did. It&amp;rsquo;s kind of like dividing by a number after multiplying by it.&lt;/p&gt;

&lt;p&gt;If we have a vector &lt;code&gt;$x$&lt;/code&gt;, and we multiply it by our matrix &lt;code&gt;$A$&lt;/code&gt;, we get &lt;code&gt;$Ax$&lt;/code&gt;. If we undo this operation by applying the inverse, we get back to &lt;code&gt;$x = A^{-1}Ax$&lt;/code&gt;. The one matrix which always leaves any vector unchanged is the identity matrix, &lt;code&gt;$I$&lt;/code&gt;. That is: &lt;code&gt;$Ix = x$&lt;/code&gt; . &lt;strong&gt;This is why &lt;code&gt;$A^{-1}A = I$&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When matrix &lt;code&gt;$A$&lt;/code&gt; has an inverse it is said to be &lt;em&gt;invertible&lt;/em&gt;. However, this is not always the case. &lt;strong&gt;When a matrix is not invertible, it is also known as&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;singular.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;3-non-invertibility-singular-matrices&#34;&gt;3. Non-Invertibility - Singular Matrices&lt;/h1&gt;

&lt;p&gt;Not all matrics are invertible. &lt;strong&gt;Matrices which are not invertible are known as&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;singular.&lt;/em&gt;&lt;/strong&gt; This means that there exists no matrix which can undo what the original matrix just did.&lt;/p&gt;

&lt;p&gt;Say we are working in two dimensions - a plane. &lt;strong&gt;Most &lt;code&gt;$2 \times 2$&lt;/code&gt; matrices will move vectors around the &lt;code&gt;$2 \times 2$&lt;/code&gt; plane.&lt;/strong&gt; They&amp;rsquo;ll either stretch them, or squash them, or even change their direction. But they&amp;rsquo;ll usually use up all of the plane; the output of that matrix multiplication won&amp;rsquo;t just be limited to a single line on that plane. The output of that matrix multiplication can &lt;strong&gt;&lt;em&gt;usually&lt;/em&gt;&lt;/strong&gt; fall anywhere on the plane.&lt;/p&gt;

&lt;p&gt;But &lt;strong&gt;if the output of a &lt;code&gt;$2 \times 2$&lt;/code&gt; matrix always lands on a single line, then there is no way to undo that operation.&lt;/strong&gt; We&amp;rsquo;ve, in effect, lost some information.&lt;/p&gt;

&lt;p&gt;This extends to higher dimensions. &lt;strong&gt;If you cannot select a vector in &lt;code&gt;$\mathbb{R}^n$&lt;/code&gt; so that the output of an &lt;code&gt;$n \times n$&lt;/code&gt; matrix multiplication with that vector can fall anywhere within the &lt;code&gt;$\mathbb{R}^n$&lt;/code&gt; hyperplane, then that &lt;code&gt;$n \times n$&lt;/code&gt; matrix is singular.&lt;/strong&gt; This means that the output of that matrix multiplication is constrained to a lower dimension (even a line, or a point).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;It&amp;rsquo;s kind of like how &lt;code&gt;$0$&lt;/code&gt; has no inverse.&lt;/strong&gt; If we have the number &lt;code&gt;$10$&lt;/code&gt;, and we multiply it by &lt;code&gt;$5$&lt;/code&gt;, we get &lt;code&gt;$50$&lt;/code&gt;. If we want to undo this operation, we multiply by &lt;code&gt;$5$&lt;/code&gt;&amp;rsquo;s (multiplicative) inverse: &lt;code&gt;$\frac {1} {5}$&lt;/code&gt; and get back &lt;code&gt;$50 \times \frac {1} {5} = 10$&lt;/code&gt;. However, if we multiply &lt;code&gt;$10$&lt;/code&gt; by &lt;code&gt;$0$&lt;/code&gt;, we get &lt;code&gt;$0$&lt;/code&gt;. There really isn&amp;rsquo;t much we can do to &lt;code&gt;$0$&lt;/code&gt; to get back to &lt;code&gt;$10$&lt;/code&gt;. This is a tenuous analogy at best, as matrices and numbers are different animals. But, hopefully this helps convey &lt;em&gt;some&lt;/em&gt; intuition.&lt;/p&gt;

&lt;h1 id=&#34;4-testing-for-singularity&#34;&gt;4. Testing for Singularity&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;There are several equivalent conditions which, if met, mean that a matrix is singular.&lt;/strong&gt; Some of these conditions are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The matrix&amp;rsquo;s determinant is 0&lt;/li&gt;
&lt;li&gt;The matrix does not have full rank&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;$n \times n$&lt;/code&gt; matrix does not have all of its pivots.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Discussions about rank and determinants are enough to warrant their own posts (and more), and are beyond the scope of this post. When I do get around to writing those posts, I&amp;rsquo;ll be sure to link them here!&lt;/p&gt;

&lt;p&gt;For now, let&amp;rsquo;s just keep in mind that not all matrices have inverses, and that if the determinant of a matrix is zero, then it doesn&amp;rsquo;t have an inverse.&lt;/p&gt;

&lt;p&gt;But if it does have an inverse, let&amp;rsquo;s try out finding it:&lt;/p&gt;

&lt;h1 id=&#34;5-inverse-of-a-2x2-matrix&#34;&gt;5. Inverse of a 2x2 Matrix&lt;/h1&gt;

&lt;p&gt;A &lt;code&gt;$2 \times 2$&lt;/code&gt; matrix has this form:&lt;/p&gt;

&lt;p&gt;\[
 \begin{bmatrix}
  a &amp;amp; b  \newline
  c &amp;amp; d
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;If a &lt;code&gt;$2 \times 2$&lt;/code&gt; matrix is invertible, then its inverse is:&lt;/p&gt;

&lt;p&gt;\[
\frac {1} {ad - bc}
\times
 \begin{bmatrix}
  d &amp;amp; -b  \newline
  -c &amp;amp; a
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$\frac {1} {ad - bc}$&lt;/code&gt; is the determinant of the matrix. If it&amp;rsquo;s zero, then we&amp;rsquo;d have &lt;code&gt;$\frac {1} {0}$&lt;/code&gt;. In other words, the inverse wouldn&amp;rsquo;t exist - our matrix would be singular.&lt;/p&gt;

&lt;p&gt;Consider the matrix:&lt;/p&gt;

&lt;p&gt;\[
A
%
&amp;#61;
%
 \begin{bmatrix}
  1 &amp;amp; 3  \newline
  2 &amp;amp; 7
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;According to our formula above, its inverse is:&lt;/p&gt;

&lt;p&gt;\[
\frac {1} {1 \times 7 - 3 \times 2}
\times
 \begin{bmatrix}
  7 &amp;amp; -3  \newline
  -2 &amp;amp; 1
 \end{bmatrix}
%
&amp;#61;
%
\frac {1} {1}
\times
 \begin{bmatrix}
  7 &amp;amp; -3  \newline
  -2 &amp;amp; 1
 \end{bmatrix}
 %
&amp;#61;
%
 \begin{bmatrix}
  7 &amp;amp; -3  \newline
  -2 &amp;amp; 1
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s verify that this is indeed the inverse in two ways.&lt;/p&gt;

&lt;h2 id=&#34;5-1-verification-1-matrix-times-inverse-equals-identity&#34;&gt;5.1 Verification #1 - Matrix times Inverse Equals Identity&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll multiply the original matrix by the inverse. If we get the identity matrix, then we&amp;rsquo;ve done our calculation correctly:&lt;/p&gt;

&lt;p&gt;\[
 \begin{bmatrix}
  1 &amp;amp; 3  \newline
  2 &amp;amp; 7
 \end{bmatrix}
  \begin{bmatrix}
  7 &amp;amp; -3  \newline
  -2 &amp;amp; 1
 \end{bmatrix}
  %
  &amp;#61;
  %
 \begin{bmatrix}
  1 \times 7 + 3 \times (-2) &amp;amp; 1 \times (-3) + 3 \times 1  \newline
  2 \times 7 + 7 \times (-2) &amp;amp; 2 \times (-3) + 7 \times 1
 \end{bmatrix}
  %
  &amp;#61;
  %
 \begin{bmatrix}
  1 &amp;amp; 0  \newline
  0 &amp;amp; 1
 \end{bmatrix}
\]&lt;/p&gt;

&lt;h2 id=&#34;5-2-verification-2-inverse-undoes-what-the-original-matrix-did&#34;&gt;5.2 Verification #2 - Inverse Undoes what the Original Matrix Did&lt;/h2&gt;

&lt;p&gt;Next, we&amp;rsquo;ll multiply a vector by the original matrix and then the result of that calculation, by the inverse. &lt;strong&gt;We should get back our original vector.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s pick the vector &lt;code&gt;$ \begin{bmatrix} 1 &amp;amp; 2 \end{bmatrix} ^ {T}$&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;\[
 \begin{bmatrix}
  1 &amp;amp; 3  \newline
  2 &amp;amp; 7
 \end{bmatrix}
  \begin{bmatrix}
  1 \newline
  2
 \end{bmatrix}
  %
  &amp;#61;
  %
 \begin{bmatrix}
  1 \times 1 + 3 \times 2 \newline
  2 \times 1 + 7 \times 2
 \end{bmatrix}
  %
  &amp;#61;
  %
  \begin{bmatrix}
  7 \newline
  16
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s now see if the inverse matrix brings  &lt;code&gt;$ \begin{bmatrix} 7 &amp;amp; 16 \end{bmatrix} ^ {T}$&lt;/code&gt; back to &lt;code&gt;$ \begin{bmatrix} 1 &amp;amp; 2 \end{bmatrix} ^ {T}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;\[
 \begin{bmatrix}
  7 &amp;amp; -3  \newline
  -2 &amp;amp; 1
 \end{bmatrix}
  \begin{bmatrix}
  7 \newline
  16
 \end{bmatrix}
  %
  &amp;#61;
  %
 \begin{bmatrix}
  7 \times 7 + (-3) \times 16 \newline
  (-2) \times 7 + 1 \times 16
 \end{bmatrix}
  %
  &amp;#61;
  %
  \begin{bmatrix}
  1 \newline
  2
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;So it looks like we&amp;rsquo;ve done our calculations correctly!&lt;/p&gt;

&lt;h1 id=&#34;6-inverse-of-a-larger-matrix&#34;&gt;6. Inverse of a Larger Matrix&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;For larger matrices, we can&amp;rsquo;t compute the inverse in the same way that we did for &lt;code&gt;$2 \times 2$&lt;/code&gt; matrices.&lt;/strong&gt; Here, we&amp;rsquo;ll employ a different strategy using &lt;a href=&#34;https://en.wikipedia.org/wiki/Gaussian_elimination&#34;&gt;Gaussian Elimination&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Say we wish to find the inverse of the 3x3 matrix:&lt;/p&gt;

&lt;p&gt;\[
A
%
&amp;#61;
%
 \begin{bmatrix}
  2 &amp;amp; -1 &amp;amp; 0  \newline
  -1 &amp;amp; 2 &amp;amp; -1 \newline
  0 &amp;amp; -1 &amp;amp; 2
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start off by creating the &lt;em&gt;augmented matrix&lt;/em&gt; &lt;code&gt;$[A \space \space I]$&lt;/code&gt;, where &lt;code&gt;$I$&lt;/code&gt; is the identity matrix:&lt;/p&gt;

&lt;p&gt;\[
[A \space \space I]
%
&amp;#61;
%
 \begin{bmatrix}
  2 &amp;amp; -1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  \newline
  -1 &amp;amp; 2 &amp;amp; -1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \newline
  0 &amp;amp; -1 &amp;amp; 2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;We then apply Gaussian Elimination, and end up with the matrix &lt;code&gt;$[I \space \space A^{-1}]$&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;\[
[I \space \space A^{-1}]
%
&amp;#61;
%
 \begin{bmatrix}
  1 &amp;amp; 0 &amp;amp; 0 &amp;amp; \frac{3} {4} &amp;amp; \frac{1} {2} &amp;amp; \frac{1} {4}  \newline
  0 &amp;amp; 1 &amp;amp; 0 &amp;amp; \frac{1} {2} &amp;amp; 1 &amp;amp; \frac{1} {2}  \newline
  0 &amp;amp; 0 &amp;amp; 1 &amp;amp; \frac{1} {4} &amp;amp; \frac{1} {2} &amp;amp; \frac{3} {4}&lt;br /&gt;
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;Yielding the inverse matrix:&lt;/p&gt;

&lt;p&gt;\[
A^{-1}
%
&amp;#61;
%
 \begin{bmatrix}
  \frac{3} {4} &amp;amp; \frac{1} {2} &amp;amp; \frac{1} {4}  \newline
  \frac{1} {2} &amp;amp; 1 &amp;amp; \frac{1} {2}  \newline
  \frac{1} {4} &amp;amp; \frac{1} {2} &amp;amp; \frac{3} {4}&lt;br /&gt;
 \end{bmatrix}
\]&lt;/p&gt;

&lt;p&gt;We can then apply the same sort of calculations that we did for the &lt;code&gt;$2 \times 2$&lt;/code&gt; case, and test that this is indeed the inverse matrix. If you don&amp;rsquo;t believe that this is in fact the inverse, then feel free to do so :) I&amp;rsquo;m going to stop right here, though!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>