<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="referrer" content="no-referrer">
  <meta name="google-site-verification" content="i-9rnKTO55VrWDag6iP74KddaTXU6YZylRl3rzB8cik" />
  

  <link rel="icon" type="image/png" href="/favicon.png">

  <title>
    
    
     r-pca 
    
  </title>
  <link rel="canonical" href="/post/r-pca/">

  <link rel="stylesheet" href="/css/fonts.css" />
  <link rel="stylesheet" href="/css/style.css" />

  
</head>

<body>
<section id=nav>
  <h1><a href="/">orrymr.com</a></h1>
  <ul>
    
    <li><a href="http://orrymr.com">Home</a></li>
    
    <li><a href="https://github.com/orrymr">GitHub</a></li>
    
    <li><a href="#">Music</a></li>
    
    <li><a href="#">About</a></li>
    
    <li><a href="https://twitter.com/orrymr">Twitter</a></li>
    
    <li><a href="/index.xml">RSS</a></li>
    
  </ul>
</section>


<section id=content>
  <h1> r-pca </h1>

  <div id=sub-header>
     · 2019/03/04 · 3 minute read
  </div>

  <p class="terms">
  
  
  Categories:
  
  <a href='/categories/data-science'>data-science</a>
  
  
  
  
  Tags:
  
  <a href='/tags/r'>R</a>
  
  <a href='/tags/pca'>pca</a>
  
  
  
  </p>

  <div class="entry-content">
    


<div id="introduction" class="section level1">
<h1>1. Introduction</h1>
<p>Principal Components Analysis (PCA) is a commonly used dimensionality reduction algorithm. In this post, we show how to perform PCA in R. This post will only briefly touch on the theory behind PCA; instead, we focus on intuition, implementation and interpretation.</p>
</div>
<div id="pca---a-brief-introduction" class="section level1">
<h1>2. PCA - A Brief Introduction</h1>
<p>PCA dates back to the early 20th century, and is used to reduce the dimensionality of data (technically, it’s a <em>linear</em> dimensionality reduction procedure. We won’t get into what that means in this post).</p>
<p>The reason you might want to do this is because high dimensional data might lie in a low dimensional subspace. We want to “re-state” this data in that lower dimensional space; that is, we want to get rid of those superfluous extra dimensions.</p>
</div>
<div id="intuition" class="section level1">
<h1>3. Intuition</h1>
<p>A simple example could be collecting data about houses in your neighbourhood; you collect features such as:</p>
<ul>
<li>Number of windows</li>
<li>Number of bedrooms</li>
<li>House price</li>
</ul>
<p>Each one of these is another dimension in your dataset. Say you mistakenly collect the area of your house both in square meters <em>and</em> in square feet. You now have 5 dimensional data, but really, it only lies in a 4 dimensional subspace.</p>
<p>This is obviously a contrived example, but hopefully you get the picture.</p>
</div>
<div id="implementation-in-r" class="section level1">
<h1>3. Implementation in R</h1>
<p>Let’s generate data which simulates some marks in two tests, a maths test and a physics test:</p>
<pre class="r"><code>set.seed(1337)
mathScore &lt;- runif(100) * 100
physicsScore &lt;- mathScore + rnorm(100, sd = 8)

#Let&#39;s make sure that there are no negative marks:
physicsScore &lt;- pmax(0, physicsScore)

#And let&#39;s make sure that there are no marks greater than 100:
physicsScore &lt;- pmin(100, physicsScore)

allTestResults &lt;- data.frame(math = mathScore, physics = physicsScore)
plot(allTestResults$math, allTestResults$physics, xlab = &quot;Math&quot;, ylab = &quot;Physics&quot;)</code></pre>
<p><img src="/post/2019-03-04-r-pca_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>We can see from the picture above that the data are pretty correlated:</p>
<pre class="r"><code>cor(allTestResults$math, allTestResults$physics)</code></pre>
<pre><code>## [1] 0.9725437</code></pre>
<p>Maybe there is some underlying, latent “smartness” dimension upon which the data truly lie. Let us attempt to determine</p>
<pre class="r"><code>pca_results &lt;- prcomp(allTestResults, center = TRUE) #Don&#39;t need to scale, since both axes already on same scale, but centering is NB

print (pca_results)</code></pre>
<pre><code>## Standard deviations (1, .., p=2):
## [1] 42.769762  5.045888
## 
## Rotation (n x k) = (2 x 2):
##                PC1        PC2
## math    -0.7050443  0.7091633
## physics -0.7091633 -0.7050443</code></pre>
<pre class="r"><code>plot(pca_results$x)</code></pre>
<p><img src="/post/2019-03-04-r-pca_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code># Let&#39;s scale the plot:
plot(pca_results$x, xlim = c(-60, 80), ylim = c(-60, 80))</code></pre>
<p><img src="/post/2019-03-04-r-pca_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>screeplot(pca_results)</code></pre>
<p><img src="/post/2019-03-04-r-pca_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>pov &lt;- pca_results$sdev^2/sum(pca_results$sdev^2)</code></pre>
<p>Percentage of variance explained by the first principal component: 98.6272283%</p>
<pre class="r"><code>biplot(pca_results)</code></pre>
<p><img src="/post/2019-03-04-r-pca_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code># allTestResults[8, ]
# allTestResults[34, ]
# allTestResults[100, ]
# allTestResults[57, ]
# allTestResults[84, ]
# allTestResults[39, ]</code></pre>
<pre class="r"><code>allTestResults[8, ]</code></pre>
<pre><code>##       math  physics
## 8 28.11173 32.83384</code></pre>
<pre class="r"><code>allTestResults[34, ]</code></pre>
<pre><code>##        math  physics
## 34 22.91205 22.28855</code></pre>
<pre class="r"><code>allTestResults[100, ]</code></pre>
<pre><code>##         math physics
## 100 97.10537     100</code></pre>
<pre class="r"><code>allTestResults[57, ]</code></pre>
<pre><code>##        math  physics
## 57 14.12764 7.651867</code></pre>
<pre class="r"><code>allTestResults[84, ]</code></pre>
<pre><code>##       math  physics
## 84 18.4879 15.14439</code></pre>
<pre class="r"><code>allTestResults[39, ]</code></pre>
<pre><code>##        math  physics
## 39 29.27543 36.10048</code></pre>
</div>

  </div>

  <div id=links>
    
      <a class="basic-alignment left" href="/post/r-tsne/">&laquo; r-tsne</a>
    
    
      <a class="basic-alignment left" href="/post/hitchhiker-s-guide-to-data-science/">Hitchhiker&#39;s Guide to Data Science &raquo;</a>
    
  </div>
</section>

<section id="comments">
<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
      
      
      if (window.location.hostname == "localhost")
                return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'orrymr';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>


  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-115127992-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>



</body>
</html>

