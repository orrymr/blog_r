---
title: Bayesian Statistics the Fun Way (My Notes)
author: ''
date: '2020-09-16'
slug: bayesian-statistics-the-fun-way-my-notes
draft: true
categories: []
tags:
  - statistics
keywords:
  - tech
---



<p>My notes on <a href="https://www.amazon.com/dp/B07J461Q2K/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">https://www.amazon.com/dp/B07J461Q2K/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1</a></p>
<!--more-->
<p>These notes are by no means (or medians) comprehensive. These are just key points in the book that I want to document and ultimately remember. I’m sure I missed some important points, but hey, I probably picked up on some important ones too.</p>
<ul>
<li><a href="#intro">Introduction</a></li>
<li><a href="#ch1">Chapter 1 - Bayesian Thinking and Everyday Reasoning</a></li>
<li><a href="#ch2">Chapter 2 - Measuring Uncertainty</a></li>
<li><a href="#ch3">Chapter 3 - The Logic of Uncertainty</a></li>
<li><a href="#ch4">Chapter 4 - Creating a Binomial Probability Distribution</a></li>
<li><a href="#ch5">Chapter 5 - The Beta Distribution</a></li>
<li><a href="#ch6">Chapter 6 - Conditional Probability</a></li>
</ul>
<div id="intro" class="section level1">
<h1>Introduction</h1>
<p>Distinction made between Frequentists and Bayesians.
<u>Frequentists</u> - probability represents frequency.
<u>Bayesian</u> - probability represents how uncertain we are about a piece of information.</p>
<p>The point is made that for coin tosses, each approach seems reasonable, but for “one-offs”, like elections, Bayesian approach makes more sense; The example of looking at probabilities associated with election results (for a given year) - Viewing the probability from a Bayesian perspective tells you about your uncertainty regarding who will win. From a Frequentist perspective, you’re making a comment about how frequently a candidate wins the 2020 election… which seems weird.</p>
</div>
<div id="ch1" class="section level1">
<h1>1. Bayesian Thinking and Everyday Reasoning</h1>
<ul>
<li>Discussion about the Bayesian process, of updating your beliefes given more data.</li>
<li>When thinking of hypotheses in Bayesian stats, we are usually concerned about how well they predict the data we observe.</li>
<li>The true heart of Bayesian analysis: <i>the test of your beliefs is how well they explain the real world.</i></li>
<li>Distinction made between <span class="math inline">\(P(D|H,X)\)</span> and <span class="math inline">\(P(H| D, X)\)</span>, where <span class="math inline">\(H\)</span> your hypothesis, <span class="math inline">\(D\)</span> is your data, and <span class="math inline">\(X\)</span> is your experience of the world. I’m going to assume that your experience of the world is implied, so really we are talking about the distinction between <span class="math inline">\(P(D|H)\)</span> and <span class="math inline">\(P(H|D)\)</span>. This point is a little tricky for me to get my head around. In the <span class="math inline">\(P(D|H)\)</span> case, we change our beliefs according to the data we gather. I guess it’s kind of like: if <span class="math inline">\(P(D|H_1)\)</span> &gt; <span class="math inline">\(P(D|H_2)\)</span>, then pick <span class="math inline">\(H_1\)</span> as your hypothesis. So, we check how well the data makes sense, given a bunch of hypotheses. Quote the book: “The data we observe is all that is real, so our beliefs ultimately need to shift until they align with the data”. Consider the other formulation: <span class="math inline">\(P(H|D)\)</span> - we’re basically saying, “probability of my beliefs (<span class="math inline">\(H\)</span>), given the data.” Or, how well does what I observe support what I believe? Seems kind of confirmation bias-y? Not sure.</li>
<li>So, it’s a question of “How well does what I observe support what I believe (<span class="math inline">\(P(H|D)\)</span>)” vs “How well does what I believe support what I observe (<span class="math inline">\(P(D|H)\)</span>)”. Great, now I have a headache. But seriously, the latter case seems more amenable to changing beliefs, while the former to changing data.</li>
</ul>
</div>
<div id="ch2" class="section level1">
<h1>2. Measuring Uncertainty</h1>
<ul>
<li>The previous chapter was more conceptual (where we just thumb sucked probabilities, like the probability of seeing an alien is “very low”), but in this chapter, try to actually quantify</li>
<li>Some axiomatic stuff about probability - like should add to 1, etc…</li>
<li>Counting outcomes of events - combinatorics.</li>
<li>Counting outcomes good for things like poker, coin tosses, etc, but what about things like “what’s the probabilty it’ll rain tomorrow?”, “Is that a UFO?”</li>
<li>Using odds to solve above problem. Say you don’t believe that a certain article exists on Wikipedia, but your annoying friend does. You reckon it’s so unlikely, you’ll give the schmuck \$100 if the article exists, and he’ll give you \$5 if it does. <span class="math inline">\(\frac{100}{5} = 20\)</span>. <span class="math inline">\(P(H_{no\_article}) = 20 \times P(H_{article})\)</span></li>
<li>$P(H_{no_article}) = 20 (1- P(H_{no_article})) $</li>
<li>$P(H_{no_article}) = 20 - 20 P(H_{no_article})) $</li>
<li>so <span class="math inline">\(P(H_{no\_article}) = \frac{20}{21}\)</span>.</li>
<li>In general <span class="math inline">\(P(H) = \frac{O(H)}{1 + O(H)}\)</span>, where <span class="math inline">\(O\)</span> is odds.</li>
<li>This chapter explored 2 different twpes of probabilities: those of events and those of beliefs.</li>
</ul>
</div>
<div id="ch3" class="section level1">
<h1>3. The Logic of Uncertainty</h1>
<ul>
<li>“AND”, leads to product rule <span class="math inline">\(P(A, B) = P(A) \times P(B)\)</span> (note, there is no discussion of independence yet…)</li>
<li>“OR”, <span class="math inline">\(P(A or B) = P(A) + P(B) - P(A \cap B)\)</span>, keeping in mind <span class="math inline">\(P(A \cap B)\)</span> will be zero when A, B mutually exclusive</li>
<li>Nice example to illustrate this point. Say you get pulled over by the cops… You need both your registration and insurance card. You’re confident that you’ve got registration, so <span class="math inline">\(P(registration) = 0.7\)</span>, not so confident about having insurance card so: <span class="math inline">\(P(insurace) = 0.2\)</span>.
So, <span class="math inline">\(P(Missing_{reg}) = 0.3\)</span> and <span class="math inline">\(P(Missing_{ins}) = 0.8\)</span>. You are worried that <u>either</u> is missing, so use the sum rule (this is an “OR” case…) Then get: <span class="math inline">\(P(Missing_{reg}) + P(Missing_{ins}) = 1.1\)</span>. Great, we fucking broke statistics. But wait… are these events mutually exclusive? Does the occurence of one mean the other cannot occur? Hell no! So, we need to subtract last term… <span class="math inline">\(P(Missing_{reg}, Missing_{ins})\)</span> = <span class="math inline">\(0.3 \times 0.8 = 0.24\)</span>, so final result <span class="math inline">\(0.86\)</span>. Note, when calculating <span class="math inline">\(P(Missing_{reg}, Missing_{ins})\)</span> we are assuming that they are independent.</li>
</ul>
</div>
<div id="ch4" class="section level1">
<h1>4. Creating a Binomial Probability Distribution</h1>
<ul>
<li>In this chapter create our first probability distribution.</li>
<li>That is, a way of describing all possible events and the probability of each one happening.</li>
<li>The “bi” part refers to 2 possible outcomes. If more than 2, then distribution is called multinomial.</li>
<li><span class="math inline">\(B(k; n, p)\)</span>. <span class="math inline">\(k\)</span>, total number of outcomes we care about, <span class="math inline">\(n\)</span> total number of trials, <span class="math inline">\(p\)</span>, probability of the event happening.</li>
<li><span class="math inline">\(B(k; n, p) = {n\choose k} \times p^k \times (1-p)^{n-k}\)</span> - this is the PMF (the pprobability mass function).</li>
<li>The binomial coefficient part of the above pmf is there to account for the number of ways you could choose k successes from n trials.</li>
<li>For example, if looking at 2 heads in 5 coin tosses, then <span class="math inline">\(5 \choose 2\)</span> is the number of ways this could happen. Could be HHTTT, HTHTT, etc…</li>
<li>Exmaple - <i>Gacha Games</i>. Purchase virtual cards with in-game currency.</li>
<li>Get a card of Bayes with p = 0.00721, Jaynes with p = 0.00720, etc… want a Jaynes card.</li>
<li>Cost 1 Bayes Buck to pull a card, can purchase 100 Bayes Bucks for \$10. Willing to buy this if you have an even chance of pulling the card you want, namely Jaynes (p = 0.00720),</li>
<li>Plug into above PMF : <span class="math inline">\({100 \choose 1} \times 0.0072^1 \times (1-0.0072)^{99}\)</span>. But, this is only for getting exactly 1 Jaynes card.</li>
<li>We need <span class="math inline">\(\sum^{100}_{k = 1} \times 0.0072 \times (1 - 0.0072)^{n-k}\)</span></li>
<li>We ain’t gonna do that by hand. If only we had some sort of device that could <em>compute</em> this for us. A computer of sorts.</li>
<li>use <code>pbinom()</code> function, can use <code>pbinom(0, 100, 0.0072, lower.tail = FALSE)</code> = 0.5145138. SO BUY THE BAYES BUCKS.</li>
<li><code>pbinom(0, 100, 0.0072, lower.tail = TRUE) + pbinom(0, 100, 0.0072, lower.tail = FALSE) = 1</code>.</li>
<li>When <code>lower.tail</code> is <code>TRUE</code>, sums up all probs less than or equal to first argument.</li>
<li>When <code>lower.tail</code> is <code>FALSE</code>, it sums up the probs scrictly greater than first argument.</li>
</ul>
</div>
<div id="ch5" class="section level1">
<h1>5. The Beta Distribution</h1>
<ul>
<li>Use beta distribution to estimtate the probability of an event for which you’ve already observed a number of trials and the number of successful outcomes.</li>
<li>For example, you would use it to estimate the probability of flipping a heads when so far you’ve observed 100 tosses of a coint, and 40 of those were heads.</li>
<li>This chapter also discusses the difference between probability, statistics and inference.</li>
<li>Division between probability and statistics - with probabilities, you have the exact figure which you use as the probability. With probability, what we’re concerned with is how likely observations are. For example, could be a 0.5 chance of getting heads - what’s the probability of getting 7 heads out of 20?</li>
<li>In statistics, look at this problem backwards - assuming you observe 7 heads in 20 coin tosses, what is the probability of getting heads in a single coin toss?</li>
<li><i>Inference</i> is the task of figuring out probabilities given the data.</li>
<li>Example: black box. Put a quarter in, sometimes 2 quarters come out, sometimes it just eats your quarter. What’s the probability of getting 2 quarters? IS it 50-50? Is it something else?</li>
<li>Try 41 quarters, get 14 wins, 27 losses.</li>
<li>Do we say <span class="math inline">\(H_1: P(two coins) = \frac{1}{2}\)</span> or <span class="math inline">\(H_2: P(two coins) = \frac{14}{41}\)</span>?</li>
<li>We can use the binomial distribution for this:</li>
<li><span class="math inline">\(P(D | H_1) = B(14;41,\frac{1}{2}) \approx 0.016\)</span></li>
<li><span class="math inline">\(P(D | H_2) = B(14;41,\frac{14}{41}) \approx 0.130\)</span></li>
<li>So, <span class="math inline">\(H_2\)</span> is almost 10x more likely, though neither is impossible.</li>
<li>We could also pick different probabilities to test:</li>
</ul>
<p><img src="https://res.cloudinary.com/da1gwmlvj/image/upload/v1601482159/bayesian_stats_fun_way/bin_at_diff_p_wdgxwv.png" /></p>
<ul>
<li>Doing this at a finer grain:</li>
</ul>
<p><img src="https://res.cloudinary.com/da1gwmlvj/image/upload/v1601483909/bayesian_stats_fun_way/bin_at_diff_p_finer_bzahpc.png" /></p>
<ul>
<li>Formalize this notion with the beta distribution.</li>
<li>Beta distribution has a probability density function (pdf) rather than pmf (like binomial), because beta is continuous.</li>
</ul>
<div class="figure">
<img src="https://res.cloudinary.com/da1gwmlvj/image/upload/v1601484058/bayesian_stats_fun_way/beta_tm4fgk.png" alt="" />
<p class="caption">Beta Distribution</p>
</div>
<ul>
<li><p><span class="math inline">\(p\)</span> - probability of an event. Corresponds to our different hypotheses for the possible probabilities of our black box.</p></li>
<li><p><span class="math inline">\(\alpha\)</span> - How many times we observe an event we care about. Like getting 2 quarters in our black box.</p></li>
<li><p><span class="math inline">\(\beta\)</span> - How many times the event we care about didn’t happen. Like number of times black box ate a quarter.</p></li>
<li><p>denominator - beta function, to normalize.
<img src="https://res.cloudinary.com/da1gwmlvj/image/upload/v1601484310/bayesian_stats_fun_way/beta_graph_sb87gj.png" /></p></li>
<li><p>Plot shows that it’s very unlikely the black box will return 2 quarters at least half the time, our break even point.</p></li>
<li><p>If we want to quantify, we need to integrate: <code>integrate(function(p) dbeta(p, 14, 27), 0, 0.5)</code> -&gt; 0.9807613 with absolute error &lt; 5.9e-06</p></li>
<li><p>Absolute error just because computers can’t perfectly calculate integrals, usually leads to a very, negligible error.</p></li>
<li><p>This result tells us that, given our evidence, there is 0.98 probability that the true probability of getting two coinds out of the black box is less than 0.5.</p></li>
<li><p>We mostly never know true probabilities for events - that’s why beta distribution is one of the most powerful tools for understanding our data.</p></li>
</ul>
</div>
<div id="ch6" class="section level1">
<h1>6. Conditional Probability</h1>
<ul>
<li>In this chapter learn how to reason about conditional probabilities - where probs are not independent.</li>
<li>Also learn about Bayes’ theorem.</li>
<li>Guillane Barre Syndrome (GBS) as incidence of 2 in 100,000</li>
<li>This can be increased if you get a flu vaccine so,
<ul>
<li>usually <span class="math inline">\(P(GBS) = \frac{2}{100000}\)</span></li>
<li>but <span class="math inline">\(P(GBS) = \frac{3}{100000}\)</span></li>
</ul></li>
<li>Conditional probabilities allow us to demonstrate how information changes our beliefs.</li>
<li>Consider colour blindness - 4.25% of people are colour blind. Caused by defective gene in X chromosome.</li>
<li>Males only have 1 X chromosome, so about 16 times more likely to be colour blind.
<ul>
<li><span class="math inline">\(P(\textrm{colour blind}) = 0.0425\)</span></li>
<li><span class="math inline">\(P(\textrm{colour blind | female}) = 0.005\)</span></li>
<li><span class="math inline">\(P(\textrm{colour blind | male }) = 0.08\)</span></li>
</ul></li>
<li>Assume male/female are split 50-50</li>
<li><span class="math inline">\(P(\textrm{male, colour bline}) = p(\textrm{male}) \times p(\textrm{colour blind} = 0.5 \times 0.0425 = 0.02125\)</span>… problem… clearer if we try product rule with females.</li>
<li><span class="math inline">\(P(\textrm{female, colour bline}) = p(\textrm{female}) \times p(\textrm{colour blind} = 0.5 \times 0.0425 = 0.02125\)</span></li>
<li>Can’t be right that the two probs are the same?!?!</li>
<li>This is because we failed failed to account for dependence between gender and colour blindness!!!</li>
<li><span class="math inline">\(P(\textrm{male, colour bline}) = p(\textrm{male}) \times p(\textrm{colour blind | male} = 0.5 \times 0.08 = 0.04\)</span></li>
<li>Thus, generalize the product rule: <span class="math inline">\(P(A, B) = P(A) \times P(B|A)\)</span></li>
<li>Also, update the sum rule: <span class="math inline">\(P(A \textrm{ or } B) = P(A) + P(B) - P(A) \times P(B|A)\)</span></li>
<li>How can we determine <span class="math inline">\(P(\textrm{male | colour blind})\)</span> ? Bayes’!</li>
<li>THe heart of Bayesian statistics is data - and right now we have 1 piece of data: that the person we’re interested in, is indeed colour blind.</li>
<li>Let <span class="math inline">\(N\)</span> represent the total propulation of people.</li>
<li>We know the person is colour blind, so we restrict to poeple who are colour blind, thus, <span class="math inline">\(P(\textrm{male | colour blind}) = \frac{\textrm{?}}{P(\textrm{colour blind} \times N)}\)</span>.</li>
<li>For the numerator, we want to calculate people who are male <i> and </i> colour blind: <span class="math inline">\(P(\textrm{male}) \times P(\textrm{colour blind | male}) \times N\)</span></li>
<li>So: <span class="math inline">\(P(\textrm{male | colour blind}) = \frac{P(\textrm{male}) \times P(\textrm{colour blind | male}) \times N}{P(\textrm{colour blind} \times N)} = 0.941\)</span> (the N’s cancel)</li>
<li>In general, Bayes’: <span class="math inline">\(P(A | B) = \frac{P(A)P(B|A)}{P(B)} = \frac{P(A \cap B)}{P(B)}\)</span></li>
<li>Think about it - the <span class="math inline">\(P(B)\)</span> goes in the denominator, because it’s the part of the world we’re restricting to. Like in the colour blind example, we only care about <span class="math inline">\(P(\textrm{colour blind})\)</span> because we <i>condition</i> on it!</li>
<li>The key takeaway here is that Bayes’ allows evidence to change the strength of our beliefs. Again, think of the colour blind example. We knew the person was colour blind. Before we knew that, we reckoned a 50% chance of them being male… but after we knew this info? 94.1% chance of them being male. Hot damn!</li>
</ul>
</div>
