---
title: The Hitchikers Guide to Inferential Statistics
author: ''
date: '0001-07-17'
slug: hitchikers-guide-to-inferential-statistics
categories: []
tags: ['hitchikers_guide', 'statistics']
keywords:
  - tech
---



<!--more-->
<div id="inferential-vs-descriptive-stats." class="section level1">
<h1>Inferential vs Descriptive stats.</h1>
<ul>
<li>Descriptive - Purely used to summarize data, like IQR, Mean. Importantly, they do not draw conclusions beyond the data we already have.</li>
<li>Inferential - Does allow us to make conclusions beyond the data we have.</li>
</ul>
<div id="hypothesis-testing" class="section level2">
<h2>Hypothesis Testing</h2>
<p>Inferential statistics is based on the premise that you can’t prove something is true, but you can disprove something by finding an exception.</p>
<p>Decide what you are trying to find evidence for (alternative hypothesis), then set up the opposite as null hypothesis, and find evidence to disprove that.</p>
<p>Suppose you want to show a link between studying and test results.</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: There is no effect on test result from studying</li>
<li><span class="math inline">\(H_1\)</span>: There is an effect on test result from studying</li>
</ul>
<p>Hypotheses are always about the population parameters (like the mean).</p>
<p>So the above should be stated mathematically:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_0\)</span> = <span class="math inline">\(\mu_1\)</span></li>
<li><span class="math inline">\(H_1\)</span>: <span class="math inline">\(\mu_0\)</span> =/= <span class="math inline">\(\mu_1\)</span></li>
</ul>
<p>If <span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\mu_1\)</span> are the means for the “no study” and “study” groups respectively.</p>
<p>General formula for test statistics: <span class="math inline">\(\frac{(Observed Data) - (What We Expect if the null is true)}{AverageVariation}\)</span>. This formula gets adapted for all the specific cases.</p>
</div>
<div id="standardization" class="section level2">
<h2>Standardization</h2>
<p>(Example from <a href="https://www.youtube.com/watch?v=uAxyI_XfqXk&amp;list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;index=19">here</a>)</p>
<p>How can we compare things that aren’t the same?</p>
<p>Suppose there are two tests: SAT and ACT.</p>
<p>Both try measure college readiness, but SAT is out of 1600 points and ACT is out of 36. How can you compare scores across these 2 tests?</p>
<ul>
<li>Centre both distributions around 0 (subtract the mean) Mean of SAT is 1000, and mean of ACT is 21, so subtract those.</li>
<li>Scales are still wrong, so divide adjusted score by standard deviation</li>
</ul>
<p>This adjusted score is called a Z-Score (see Definitions). <span class="math inline">\(Z = \frac{x - \mu}{\sigma}\)</span>.</p>
<p>Note the assumption that both the distribution of SAT and ACT are normally distributed!</p>
</div>
<div id="normal-distribution" class="section level2">
<h2>Normal Distribution</h2>
<p>(Based on <a href="https://www.youtube.com/watch?v=rBjft49MAO8&amp;list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;index=20">here</a>)</p>
<p>Normal distribution is important not only because a lot of things are normally distributed, like, height, IQ etc… There are a lot of things like debt, blood pressure which are not normally distributed. But here’s the thing - distributions of means are normally distributed, even if populations aren’t. So, if you sample a lot from a population which is not distributed normally, the mean of those samples will be normally distributed!</p>
<p>In order to meaningfully compare whether two means are different, we need to know something about their distribution: the sampling distribution.</p>
<p>This is described formally in the <strong>Central Limit Theorem</strong> (see definitions).</p>
<p><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-2-1.png" width="672" /><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-2-2.png" width="672" /><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-2-3.png" width="672" /><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-2-4.png" width="672" /><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-2-5.png" width="672" /><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-2-6.png" width="672" /><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-2-7.png" width="672" /><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-2-8.png" width="672" /></p>
<p>Now, the mean of the distribution of sample means is the same as the population mean, its standard deviation is not.</p>
<p>However, the standard deviation of the distribution of sample means <em>is</em> related to the standard deviation of the population. But, it’s also related to the sample size. In the above graphs, see how the probability distributions of the graphs get thinner, as the number of dice goes up? The bigger your sample size, the closer your sample means are to the true population mean. So we need to adjust the original population standard deviation somehow to reflect this:</p>
<p><span class="math inline">\(\sigma_{samplingDistribution} = \frac{\sigma_{population}}{\sqrt{n}}\)</span></p>
<p>The standard deviation of a sampling distribution is called the <em>standard error</em>.</p>
<p>Note here that the number of rolls does not affect the shape of the distribution, only how accurately we approximate it. Think about it, the true shape is determined by the number of dice we have. If we have fewer dice, we expect the mean value we get for them to fluctuate more wildly.</p>
<p><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-3-1.png" width="672" /><img src="/post/post/hhguides/2020-07-17-hitchikers-guide-to-inferential-statistics_files/figure-html/unnamed-chunk-3-2.png" width="672" /></p>
<p>Can also use sampling distributions to compare other parameters - proportions, regression coefficients, or standard deviations, which also follow the central limit theorem.</p>
</div>
<div id="t-distribution" class="section level2">
<h2>T-Distribution</h2>
<p><a href="https://www.youtube.com/watch?v=yDEvXB6ApWc&amp;list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;index=21">They talk about T-dist closer to end of this vid</a></p>
<p>Continous, unimodal probability distribution that’s useful to represent sampling distributions. It changes its shape based on how much information there is. It’s got thicker tails for smaller sample sizes (as there is less information) - making the distribution less “tight” around the mean - showing that we’re more uncertain. For bigger and bigger sample sizes the distribution gets thinner tails, and eventually becomes the same as the normal distribution. Usually, for tests about means sample sizes &gt;= 30, it’s usually the same as normal. For proportions, need at least 10 instances from each group in the proportion!</p>
</div>
<div id="hypothesis-testing-applied" class="section level2">
<h2>Hypothesis Testing Applied</h2>
<p>Cool definition from <a href="here">https://youtu.be/bf3egy7TQ2Q?list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;t=281</a>:</p>
<p><u>Null Hypothesis Significance Testing</u> is a form of the reductio ad absurdum argument which tries to discredit an idea by assuming the idea is true, and then showing that if you make that assumption, something contradictory happens.</p>
<p>(Just some examples of reductio ad absurdum outside of stats: The Earth cannot be flat; otherwise, we would find people falling off the edge. There is no smallest positive rational number because, if there were, then it could be divided by two to get a smaller one. It’s like proof by contradiction.)</p>
<div id="p-value" class="section level3">
<h3>P Value</h3>
<p>A P-Value answers the question of how rare your data is, by telling you the probability of getting data that’s extreme as the data you observed, if the null hypothesis were true. P-value tells you is how extreme your sample is assuming that the null is true.</p>
<p>P-value = 0.1, then sample is in the top 10% most extreme samples we’d expect to see based on the distribution of sample means.</p>
<p>A 2-sided p-value will tell us the probability of getting a sample mean as extreme (on either side) as the one we’ve seen, under the null hypothesis. A 1 sided will tell us the probability of getting a sample mean as high (or low) as the one we’ve seen, under the null hypothesis.</p>
<p>NB: On Common misinterpretation of the a p-value is that it can telly ou the probability that the null hypothesis is true - <a href="https://youtu.be/PPD8lER8ju4?list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;t=234">IT CAN’T!</a> Ronald Fisher said: “In general, tests of significance are based on hypothetical probabilities calculated from their null hypotheses. They do no generally lead to any probability statements about the real word, but to a rational and well-defines measure of reluctance to the acceptance of the hypotheses they test.” So, getting a p-value of 0.1 doesn’t mean there is a 10% chance the null hypothesis is true.</p>
<p>If P-Value is not lower than alpha, then we fail to reject <span class="math inline">\(H_0\)</span>. Notice that we say fail to rehect, not accept. Null hypothesis testing doesn’t allow us to “accept” or provide evidence that the null is true, instead we’ve only failed to provide evidence that it’s false. Abscense of evidence is not the evidence of abscense. Failint to reject the null doesn’t mean thtere isn’t an effect or relationship, just means we didn’t get enough evidence to say there definitely is one.</p>
</div>
<div id="z---test-vs-t---test" class="section level3">
<h3>Z - test vs T - test</h3>
<p>Z - tests commonly done when population standard deviation is known. T - tests commonly done when population standard deviation is unknown. We use t - distribution because the unknown population standard deviation is now a value we must estimate.</p>
</div>
<div id="one-sample-z---test" class="section level3">
<h3>One Sample Z - Test</h3>
<p><a href="https://www.youtube.com/watch?v=BWJRsY-G8u0">From here</a>.</p>
<p>In the population the average IQ is 100 with a s.d. of 15. Give a sample of 30 participants a drug which either makes them smarter, stupider or has no effect. The sample of 30 people has a mean of 140. Did the medication affect intelligence?</p>
<p>Note here that the population standard deviation and mean is given. Very importantly, we’re testing a mean, the sample mean. The question we’re basically asking is how probable is it that we saw a sample mean of 140? Now, recall, from the above, sample means are distributed normally. And they will be centered around the population mean. And that the sample standard deviation is related to the population standard deviation. But remember, it’s actually the sample mean standard deviation, which gets thinner as we get more observations.</p>
<p>So, the normal distribution in the one sample Z-test is actually the distribution of sample means, under the null hypothesis. Mkay?</p>
<p><span class="math inline">\(Z = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}} = 14.60\)</span></p>
<p>Let’s take an <span class="math inline">\(\alpha = 0.05\)</span> (which corresponds to Type I error happening 5% of the time - Type I error is the probability of rejecting Null Hypothesis even though the Null is correct). This is a 2 - tailed test, so rehect if Z less than -1.96 or greater than 1.96 :) HERE WE REJECT NULL HYPOTHESIS.</p>
</div>
<div id="one-sample-z--test-for-proportions" class="section level3">
<h3>One Sample Z- Test for proportions</h3>
<p><a href="https://www.youtube.com/watch?v=dH6igFVoCAw&amp;list=PL568547ACA9211CCA&amp;index=61">From here</a></p>
<p>Survery claims 9/10 docs recommend aspirin. Survery, random sample, of 100 docs. 82 claim they recommend aspirin. At alpha = 0.05, do we believe?</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(p = 0.9\)</span> <span class="math inline">\(H_q\)</span>: <span class="math inline">\(p \neq 0.9\)</span></p>
<p>The test statistic:</p>
<p><span class="math inline">\(Z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}} = -2.667\)</span></p>
<p><span class="math inline">\(\hat{p} = 0.82\)</span> <span class="math inline">\(p_0 = 0.9\)</span> <span class="math inline">\(n = 100\)</span></p>
<p>I think this comes from Bernoulli… Mean of Bernoulli is <span class="math inline">\(p_0 = 0.9\)</span> and variance is <span class="math inline">\(p_0(1 - p_0) = 0.9 \times 0.1 = 0.09\)</span></p>
<p>So, really I think you can derive the test for proportions from the initial equation:</p>
<p><span class="math inline">\(Z = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}}\)</span></p>
<p>Except now, the population mean under the Null Hypothesis is <span class="math inline">\(p_0\)</span>, the sample mean is <span class="math inline">\(0.82\)</span>, the population variance, under the Null is <span class="math inline">\(0.9(1 - 0.1)\)</span>, which makes the sample mean’s s.d. <span class="math inline">\(\sqrt{\frac{p_0(1-p_0)}{n}}\)</span>. The thing about the Bernoulli is that if you’ve got the mean, you’ve got the variance.</p>
<p>Anyway, -2.667 &lt; -1.96 so reject <span class="math inline">\(H_0\)</span>.</p>
</div>
<div id="one-sample-t---test" class="section level3">
<h3>One sample t - test</h3>
<p>Population, average IQ = 100. New medication, either has negative, positive or no effect on intelligence. Sample of 30 participants have taken med, end up with a mean of 140 and s.d. of 20. Did medication affect intelligence?</p>
<p><span class="math inline">\(H_0; \mu = 100\)</span> <span class="math inline">\(H_1; \mu \neq 100\)</span></p>
<p>Degrees of freedom= <span class="math inline">\(n - 1 = 30 - 1 = 29\)</span>.</p>
<p>Critical values: -2.0452 &amp; 2.0452.</p>
<p><span class="math inline">\(t = \frac{\bar{x} - \mu}{s / \sqrt{n}} = 10.96\)</span>, reject <span class="math inline">\(H_0\)</span>.</p>
</div>
<div id="t-test---degrees-of-freedom-and-effect-size" class="section level3">
<h3>T Test - Degrees of Freedom and Effect Size</h3>
<p>T-Distribution is like Z-Distribution, but has fatter tails.</p>
<p>Recall, we don’t know the population standard deviation in a T-Test. So, we estimate it using the sample standard deviation. So, we don’t have a perfect normal dist. But with bigger sample sizes, we’re better at estimating standard deviation, so T-Dist changes to look more and more like normal. More info means we’re more accurate. Degrees of Freedom can help us choose that accuracy.</p>
<p>Number of independent pieces of information we have in our data. If have 3 observations, and we know the mean of those 3 observations, and the value of 2 of the 3 observations, the last observations <em>has to</em> take on a certain value, for the mean to equal what it does. The last observation is not “Free” to take on any value. By contrast, if you know the mean of 3 observations, and only know the actual value of 1, the last 2 observations are free to take on a whole range of values.</p>
<p>In terms of t-test: When we calc the mean, we use up 1 of those degrees of freedom, or 1 piece of independent info. Amount of info we have, depends on our sample size <span class="math inline">\(n\)</span>. The more data you have, the more independent info that you have - but every time you make a calc like the mean, you’re using up 1 piece of independent information.</p>
</div>
<div id="effect-size-and-significance" class="section level3">
<h3>Effect Size and Significance</h3>
<p>You can sometimesm find that there is a statistically significant difference in 2 means, which might be what you wanted. But the effect size is so small (compared to random variation), that it may not be worth it. For example, a hair vitamin might cause your hair to grow a statistically significant extra couple of nano-meters per month, but since you hair grows 12 mm per month, and the vitamin is expensive, it may not be <em>practically significant</em> for you to buy it.</p>
<p>NB, recall that in your t test statistic, the denominator is scaled by the sample size; so the smaller the sample size, the smaller the scaled standard error: <span class="math inline">\(\frac{SE}{\sqrt{n}}\)</span>, the bigger the t test stat. If the numerator is very small (ie, the effect size if very small), then even if there is an effect, the only way to test it might be to increase the sample size, in order to get your t-test stat to be bigger.</p>
<p><span class="math inline">\(t = \frac{\bar{x_1} - \bar{x_2}}{\sqrt{\frac{S^2_{control}}{n_{control}} + \frac{S^2_{treatment}}{n_{treatment}}}}\)</span> - in the 2 sample case. See how a small effect size (numerator) need much <span class="math inline">\(n_{i}\)</span>s to pick up significance (that is, for t stat to be bigger)?</p>
<p><b>So, P values should always be looked at WITH effect size.</b></p>
<p><u> <b>We need degrees of freedom to understand why smaller differences between means can be significant if you have a larger sample size! </b></u>. The more info you have, the more accurate your estiamtes are.</p>
<p>So, fewer degrees of freedom -&gt; the fatter the tails, and the less likely your are to reject the null. More data though, means more degrees of freedom and thinner tails, so the more confident you are in extreme values, and thus more likely to reject the null when seeing them.</p>
</div>
</div>
<div id="confidence-intervals" class="section level2">
<h2>Confidence Intervals</h2>
<p>The mean of sample distribution is the center a CI (see definition below). The way we choose the confidence range is related to the distribution of sample means (depends on standard deviation of sample means.).</p>
<p>The 95% in a 95% confidence interval tells us that if we calculated a confidence interval from 100 different samples, about 95% of them would contain the true population mean. Think about it, if you got 2 different samples of 40 people, both of those would have different sample means and sample standard deviations, and thus different confidence intervals. It is possible the CI we’ve created doesn’t contain the true mean.</p>
</div>
<div id="bayes-theorem" class="section level2">
<h2>Bayes’ Theorem</h2>
<p><span class="math inline">\(P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{P(A \cap B)}{P(B)}\)</span></p>
<p>Updating beliefs.</p>
<p>Suppose your sister tells you she has a friend. At this point, 50-50 chance that it’s male / female. Suppose your sister also tells you that the friend has breast cancer. Then <span class="math inline">\(P(male | BREAST CANCER) = \frac{P(BREAST CANCER | male)P(male)}{P(BREAST CANCER)}\)</span> Suppose you know <span class="math inline">\(P(BREAST CANCER | male) and P(BREAST CANCER)\)</span> from gov’t statistics, then you can calc: <span class="math inline">\(P(male | BREAST CANCER) = \frac{P(0.001)P(0.5)}{P(0.063)} = 0.79%\)</span>, so pretty low.</p>
<p>So, in the above, we updated our belief based on new information. Rearrange the formula slightly to see this more clearly: $P(A|B) = P(A) $ <span class="math inline">\(P(male | BREAST CANCER) = \frac{P(0.001)}{P(0.063)}P(A)\)</span></p>
<p>Updating beliefs is core to Bayesian stats.</p>
<p>Bayes’ Factor… Say you’re trying to figure out if someone is a star wars fan. Say your <em>prior</em> belief is that 60% of people are Star Wars fans. ie, <span class="math inline">\(P(fan) = 0.6\)</span> Suppose also, that the probabilty of watching a new star wars movie that’s just come out is <span class="math inline">\(P(movie | fan) = 0.99\)</span>, as fans would rush to watch it. But suppose also that the probability of watching the movie given that a person is not a fan is <span class="math inline">\(P(movie | not fan) = 0.5\)</span>. This is because some people are just curious about it, (like me), or dragged by friends / family. So <span class="math inline">\(\frac{P(movie | fan)}{P(movie | not fan)} = \frac{0.99}{0.5} = 1.98\)</span> is the odds that a person is a fan, if they tell you that they’ve watched the movie. It’s what we’ve learned about they hypothesis from the data (in this case the data is someone telling you they’ve watched the movie). We cam multiply our <em>prior</em> with this factor to get our posterior.</p>
<p>We can repeat this process; make the new posterior a prior for updating beliefs. In the example before, let’s say that there are 60% star wars fans and 40% not - this is your prior. So, odds you’re a fan is <span class="math inline">\(\frac{0.6}{0.4} = 1.5\)</span>. But we can update this with the data: <span class="math inline">\(\frac{0.6}{0.4} \times \frac{0.99}{0.5} = 1.5 \times 1.98 = 2.97\)</span>; so the odds have increased.</p>
<div id="bayesian-hypothesis-testing" class="section level3">
<h3>Bayesian Hypothesis Testing</h3>
<p>Compare the probabilities of the 2 hypotheses: from the above, compare the probabilities of the probability that a person is a fan, given they’d seen the movie. So, compare <span class="math inline">\(P(fan | seenmovie)\)</span> and <span class="math inline">\(P(not fan | seenmovie)\)</span>.</p>
<p>So look that the ratio: <span class="math inline">\(\frac{P(fan | seenmovie)}{P(not fan | seenmovie)}\)</span>. We look at the ratio of 2 instances of Bayes’ thm; since both the numerator and the denominator are posterior probs.</p>
</div>
<div id="criticism-of-bayes" class="section level3">
<h3>Criticism of Bayes’</h3>
<p>In Bayesian hypothesis testing (also in just applying Bayes’ thm), the result is influenced by your prior <em>belief</em>. If you throw in a different number for your belief, then you get different results.</p>
<p>One of the main uses of statistics is science whis is supposed to be relatively “objective” and not influenced by opinion, yet here’s a method that included beliefs in its calculation.</p>
<p>In some research, the researchers publish the Bayes Factor, for just this reason - it’s free of the prior. You could then use their calculated Bayes factor to update your own prior.</p>
</div>
<div id="bayesian-inference" class="section level3">
<h3>Bayesian Inference</h3>
<p>Using Bayesian methods to analyze questions allows us to “inject” <em>prior beliefs</em> into the analysis.</p>
<p>Using Null Hypothesis significance testing, we can ask whether means of groups are likely different, or not (reject, or fail to reject null hypothesis - recall, you can only fail to reject the null hypothesis, that is, you don’t state that the means are the same, just that you haven’t seen enough evidence to show they aren’t). With Bayesian methods, you can assign a probability to the question of whether or not the means are different. It’s not just a binary outcome… (I think…)</p>
<p>Bayesian A/B Testing: <a href="https://www.countbayesie.com/blog/2015/4/25/bayesian-ab-testing" class="uri">https://www.countbayesie.com/blog/2015/4/25/bayesian-ab-testing</a> ^^ In the above he also mentions why to use instead of using t-tests for differences of means. “Classical statistics tells us Significance, but what we’re really after is Magnitude!” - sayeth Count Bayesie.</p>
</div>
</div>
<div id="chi-square-tests" class="section level2">
<h2>Chi Square Tests</h2>
<p>Model fits? Compare expectations vs observations.</p>
<p>Discrete. Contingency tables.</p>
<p>Test = <span class="math inline">\(\frac{Observed - ExpecetedUnderNullHypothesis}{AverageVariation}\)</span></p>
<p>What’s Average Variation?</p>
<p>If we just take observed minus expected, we always get to 0, so we square the answers before adding.</p>
<p>Chi sq, degrees of freedom - all the counts, minus 1 (same argument as t-test d.o.f). Can find p-val.</p>
<p>Types of Chisq test:</p>
<div id="goodness-of-fit" class="section level3">
<h3>Goodness of fit</h3>
<p>Only has 1 row. Expected frequency must be &gt; 5.</p>
</div>
<div id="test-of-independence" class="section level3">
<h3>Test of independence</h3>
<p>Tests whether being a member of 1 category is independent of being in another.</p>
</div>
<div id="test-of-homogeneity" class="section level3">
<h3>Test of homogeneity</h3>
<p>Tests whether it’s likely thatn 2 samples come from the same population.</p>
<p>d.o.f = (r-1)(c-1).</p>
</div>
</div>
<div id="glm---general-linear-model" class="section level2">
<h2>GLM - General Linear Model</h2>
<p>Allow us to create many different models, like the regression model.</p>
<p>GLM overview: Data = Model + Error.</p>
<p>ie, <span class="math inline">\(y = b + mx\)</span>. (error is b; model part is mx)</p>
<p>Error is a deviation in model.</p>
<div id="linear-regression" class="section level3">
<h3>Linear Regression</h3>
<p>Assumption is that data is linear. Regression line is the line that’s as close as possible to all data points at once. Ie, minimizes Sum of squared distances from line.</p>
<p>Residual plot - plot the errors.</p>
<p>F-Test -&gt; quantify how well we think our data fit a distribution, like the null distribution.</p>
<p>Recall, in general, a Test Stat = <span class="math inline">\(\frac{ObservedData - WhatWeExpectIfTheNullIsTrue}{AverageVariation}\)</span>.</p>
<p>F-stat = <span class="math inline">\(\frac{ObservedModel - ModelIfNullIsTrue}{AverageVariation}\)</span>.</p>
<p>Consider total sum of squares: <span class="math inline">\(\sum(y_i -\bar{y}) ^ 2\)</span> &lt;- total variation in the dataset. We want to know how much of that variation is accounted for in our model, and how much is just error. (good explanation)[<a href="https://youtu.be/WWqE7YHR4Jc?list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;t=424" class="uri">https://youtu.be/WWqE7YHR4Jc?list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;t=424</a>] - but the idea is, that from the data we calculate some slope coefficient, <span class="math inline">\(\hat{\beta}\)</span>, let’s say <span class="math inline">\(\hat{\beta} = 6.468\)</span>. We want to know what the difference would be if we assumed no relationship, ie <span class="math inline">\(\hat{\beta} = 0\)</span>.</p>
<p><span class="math inline">\(F-stat = \frac{SSR}{Average Variation}\)</span> - numerator, sum of squares for regression, is the difference between the models using the calculated slope, and a slope of 0. Bottom part is SSE.</p>
<p><b>F statistic allows us to directly compare the amount of variation can and cannot explain</b>.</p>
<p><span class="math inline">\(t^2 = F\)</span></p>
</div>
<div id="anova" class="section level3">
<h3>ANOVA</h3>
<p>Test the difference between multiple groups.</p>
<p>Similar to regression, except use a categorical to predict an outcome. Like using degree studied for vs salary.</p>
<p>Note, Anova can tell you that there is a statistically significant difference between the groups, but not where it is. So follow up with multiple t-tests (Bonferroni).</p>
<p>The ANOVA makes an assumption about the world which it tests: that the best prediction for a variable is the mean rating of the group it belongs to!</p>
<p>RA Fisher.</p>
</div>
</div>
</div>
<div id="definitions" class="section level1">
<h1>Definitions</h1>
<ul>
<li><u>Bayes’ Factor</u> - Represents the amount of info we’ve learned about our hypotheses from the data.</li>
<li><u>Central Limit Theorem</u> - The distribution of sample means for an independent random variable will get closer and closer to a normal distribution as the size of the sample gets bigger and bigger, even if the original population distribution isn’t normal. Think of independet die rolls, like in <a href="https://youtu.be/rBjft49MAO8?list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;t=349">here</a>. Twenty dice are 20 independent random variables.</li>
<li><u>Confidence Interval</u> - An <b>estimated range of values</b> that seem reasonable based on what we’ve observed. Its center is still the <b>sample mean</b>, but we’ve got some room on either side for out uncertainty.</li>
<li><u>Degrees of freedom </u> Number of independent pieces of information we have -<u>Effect Size </u> - How big the effect we observed was, compared to random variation</li>
<li><u>Hypthesis Testing</u> -</li>
<li><u>Inference</u> - the process of drawing conclusions about population parameters based on a sample taken from the population.</li>
<li><u>P-Value</u> - probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.</li>
<li><u>Point Estimate </u> - a single value given as an estimate of a parameter of a population. Like the mean.</li>
<li><u>Regression Line </u> - Regression line is the line that’s as close as possible to all data points at once.</li>
<li><u>Sampling distribution</u> - the probability distribution of a sample statistic (like the mean, or variance).</li>
<li><u>Standard Error</u> - of a statistic (usually an estimate of a parameter - like the mean) is the standard deviation of its sampling distribution. For example, Standard error of the mean is <span class="math inline">\(\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}\)</span></li>
<li><u>Statistical Power </u> - <span class="math inline">\(1 - \beta\)</span> - chance of detecting an effect if there is one.</li>
<li><u>Test Statistic </u> - Allow us to quantify how close things are to our expectations or theories</li>
<li><u>Type I error</u> - <span class="math inline">\(\alpha\)</span> - probability of saying null hypothesis is wrong, when it is correct</li>
<li><u>Type II error</u> - <span class="math inline">\(\beta\)</span> - probability of not saying the null hypothesis is wrong, even though it is wrong. Note, you’re not actually saying it’s true, just that it’s not wrong.</li>
<li><u>Z-Distrubtion</u> - Standardized normal distribution</li>
<li><u>Z-Score</u> - A Z-score is a numerical measurement that describes a value’s relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean. If a Z-score is 0, it indicates that the data point’s score is identical to the mean score. A Z-score of 1.0 would indicate a value that is one standard deviation from the mean. <strong>Z scores allow us to compare things that are not on the same scale as long as they are normally distributed</strong>.</li>
</ul>
</div>
