---
title: Bayesian Statistics the Fun Way (My Notes)
author: ''
date: '2020-09-16'
slug: bayesian-statistics-the-fun-way-my-notes
draft: true
categories: []
tags:
  - statistics
keywords:
  - tech
---

My notes on [https://www.amazon.com/dp/B07J461Q2K/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1](https://www.amazon.com/dp/B07J461Q2K/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1)

<!--more-->

These notes are by no means (or medians) comprehensive. These are just key points in the book that I want to document and ultimately remember. I'm sure I missed some important points, but hey, I probably picked up on some important ones too.

- [Introduction](#intro)
- [Chapter 1 - Bayesian Thinking and Everyday Reasoning](#ch1)
- [Chapter 2 - Measuring Uncertainty](#ch2)
- [Chapter 3 - The Logic of Uncertainty](#ch3)
- [Chapter 4 - Creating a Binomial Probability Distribution](#ch4)
- [Chapter 5 - The Beta Distribution](#ch5)
- [Chapter 6 - Conditional Probability](#ch6)

# Introduction {#intro}

Distinction made between Frequentists and Bayesians. 
<u>Frequentists</u> - probability represents frequency.
<u>Bayesian</u> - probability represents how uncertain we are about a piece of information.

The point is made that for coin tosses, each approach seems reasonable, but for "one-offs", like elections, Bayesian approach makes more sense; The example of looking at probabilities associated with election results (for a given year) - Viewing the probability from a Bayesian perspective tells you about your uncertainty regarding who will win. From a Frequentist perspective, you're making a comment about how frequently a candidate wins the 2020 election... which seems weird.


# 1. Bayesian Thinking and Everyday Reasoning {#ch1}
 
- Discussion about the Bayesian process, of updating your beliefes given more data.
- When thinking of hypotheses in Bayesian stats, we are usually concerned about how well they predict the data we observe.
- The true heart of Bayesian analysis: <i>the test of your beliefs is how well they explain the real world.</i>
- Distinction made between $P(D|H,X)$ and $P(H| D, X)$, where $H$ your hypothesis, $D$ is your data, and $X$ is your experience of the world. I'm going to assume that your experience of the world is implied, so really we are talking about the distinction between $P(D|H)$ and $P(H|D)$. This point is a little tricky for me to get my head around. In the $P(D|H)$ case, we change our beliefs according to the data we gather. I guess it's kind of like: if $P(D|H_1)$ > $P(D|H_2)$, then pick $H_1$ as your hypothesis. So, we check how well the data makes sense, given a bunch of hypotheses. Quote the book: "The data we observe is all that is real, so our beliefs ultimately need to shift until they align with the data". Consider the other formulation: $P(H|D)$ - we're basically saying, "probability of my beliefs ($H$), given the data." Or, how well does what I observe support what I believe? Seems kind of confirmation bias-y? Not sure.
- So, it's a question of "How well does what I observe support what I believe ($P(H|D)$)" vs "How well does what I believe support what I observe ($P(D|H)$)". Great, now I have a headache. But seriously, the latter case seems more amenable to changing beliefs, while the former to changing data.

# 2. Measuring Uncertainty {#ch2}

- The previous chapter was more conceptual (where we just thumb sucked probabilities, like the probability of seeing an alien is "very low"), but in this chapter, try to actually quantify
- Some axiomatic stuff about probability - like should add to 1, etc...
- Counting outcomes of events - combinatorics.
- Counting outcomes good for things like poker, coin tosses, etc, but what about things like "what's the probabilty it'll rain tomorrow?", "Is that a UFO?"
- Using odds to solve above problem. Say you don't believe that a certain article exists on Wikipedia, but your annoying friend does. You reckon it's so unlikely, you'll give the schmuck \\\$100 if the article exists, and he'll give you \\\$5 if it does. $\frac{100}{5} = 20$. $P(H_{no\_article}) = 20 \times P(H_{article})$ 
- $P(H_{no\_article}) = 20 \times (1- P(H_{no\_article})) $
- $P(H_{no\_article}) = 20 - 20 \times P(H_{no\_article})) $
- so $P(H_{no\_article}) = \frac{20}{21}$. 
- In general $P(H) = \frac{O(H)}{1 + O(H)}$, where $O$ is odds.
- This chapter explored 2 different twpes of probabilities: those of events and those of beliefs.

# 3. The Logic of Uncertainty {#ch3}

- "AND", leads to product rule $P(A, B) = P(A) \times P(B)$ (note, there is no discussion of independence yet...)
- "OR", $P(A or B) = P(A) + P(B) - P(A \cap	B)$, keeping in mind $P(A \cap	B)$ will be zero when A, B mutually exclusive
- Nice example to illustrate this point. Say you get pulled over by the cops... You need both your registration and insurance card. You're confident that you've got registration, so $P(registration) = 0.7$, not so confident about having insurance card so: $P(insurace) = 0.2$.
So, $P(Missing_{reg}) = 0.3$ and $P(Missing_{ins}) = 0.8$. You are worried that <u>either</u> is missing, so use the sum rule (this is an "OR" case...) Then get: $P(Missing_{reg}) + P(Missing_{ins}) = 1.1$. Great, we fucking broke statistics. But wait... are these events mutually exclusive? Does the occurence of one mean the other cannot occur? Hell no! So, we need to subtract last term... $P(Missing_{reg}, Missing_{ins})$ = $0.3 \times 0.8 = 0.24$, so final result $0.86$. Note, when calculating $P(Missing_{reg}, Missing_{ins})$ we are assuming that they are independent.

# 4. Creating a Binomial Probability Distribution {#ch4}

- In this chapter create our first probability distribution.
- That is, a way of describing all possible events and the probability of each one happening.
- The "bi" part refers to 2 possible outcomes. If more than 2, then distribution is called multinomial.
- $B(k; n, p)$. $k$, total number of outcomes we care about, $n$ total number of trials, $p$, probability of the event happening.
- $B(k; n, p) = {n\choose k} \times p^k \times (1-p)^{n-k}$ - this is the PMF (the pprobability mass function).
- The binomial coefficient part of the above pmf is there to account for the number of ways you could choose k successes from n trials.
- For example, if looking at 2 heads in 5 coin tosses, then $5 \choose 2$ is the number of ways this could happen. Could be HHTTT, HTHTT, etc...
- Exmaple - <i>Gacha Games</i>. Purchase virtual cards with in-game currency.
- Get a card of Bayes with p = 0.00721, Jaynes with p = 0.00720, etc... want a Jaynes card.
- Cost 1 Bayes Buck to pull a card,  can purchase 100 Bayes Bucks for \\\$10. Willing to buy this if you have an even chance of pulling the card you want, namely Jaynes (p = 0.00720), 
- Plug into above PMF : ${100 \choose 1} \times 0.0072^1 \times (1-0.0072)^{99}$. But, this is only for getting exactly 1 Jaynes card.
- We need $\sum^{100}_{k = 1} \times 0.0072 \times (1 - 0.0072)^{n-k}$
- We ain't gonna do that by hand. If only we had some sort of device that could _compute_ this for us. A computer of sorts.
- use `pbinom()` function, can use `pbinom(0, 100, 0.0072, lower.tail = FALSE)` = 0.5145138. SO BUY THE BAYES BUCKS.
- `pbinom(0, 100, 0.0072, lower.tail = TRUE) + pbinom(0, 100, 0.0072, lower.tail = FALSE) = 1`.
- When `lower.tail` is `TRUE`, sums up all probs less than or equal to first argument.
- When `lower.tail` is `FALSE`, it sums up the probs scrictly greater than first argument.

# 5. The Beta Distribution {#ch5}

- Use beta distribution to estimtate the probability of an event for which you've already observed a number of trials and the number of successful outcomes.
- For example, you would use it to estimate the probability of flipping a heads when so far you've observed 100 tosses of a coint, and 40 of those were heads.
- This chapter also discusses the difference between probability, statistics and inference.
- Division between probability and statistics - with probabilities, you have the exact figure which you use as the probability. With probability, what we're concerned with is how likely observations are. For example, could be a 0.5 chance of getting heads - what's the probability of getting 7 heads out of 20?
- In statistics, look at this problem backwards - assuming you observe 7 heads in 20 coin tosses, what is the probability of getting heads in a single coin toss?
- <i>Inference</i> is the task of figuring out probabilities given the data.
- Example: black box. Put a quarter in, sometimes 2 quarters come out, sometimes it just eats your quarter. What's the probability of getting 2 quarters? IS it 50-50? Is it something else?
- Try 41 quarters, get 14 wins, 27 losses.
- Do we say $H_1: P(two coins) = \frac{1}{2}$ or $H_2: P(two coins) = \frac{14}{41}$?
- We can use the binomial distribution for this:
- $P(D | H_1) = B(14;41,\frac{1}{2}) \approx 0.016$
- $P(D | H_2) = B(14;41,\frac{14}{41}) \approx 0.130$
- So, $H_2$ is almost 10x more likely, though neither is impossible. 
- We could also pick different probabilities to test:

![](https://res.cloudinary.com/da1gwmlvj/image/upload/v1601482159/bayesian_stats_fun_way/bin_at_diff_p_wdgxwv.png)

- Doing this at a finer grain:

![](https://res.cloudinary.com/da1gwmlvj/image/upload/v1601483909/bayesian_stats_fun_way/bin_at_diff_p_finer_bzahpc.png)

- Formalize this notion with the beta distribution.
- Beta distribution has a probability density function (pdf) rather than pmf (like binomial), because beta is continuous.

![Beta Distribution](https://res.cloudinary.com/da1gwmlvj/image/upload/v1601484058/bayesian_stats_fun_way/beta_tm4fgk.png)

- $p$ - probability of an event.  Corresponds to our different hypotheses for the possible probabilities of our black box.
- $\alpha$ - How many times we observe an event we care about. Like getting 2 quarters in our black box.
- $\beta$ - How many times the event we care about didn't happen. Like number of times black box ate a quarter.
- denominator - beta function, to normalize.
![](https://res.cloudinary.com/da1gwmlvj/image/upload/v1601484310/bayesian_stats_fun_way/beta_graph_sb87gj.png)
- Plot shows that it's very unlikely the black box will return 2 quarters at least half the time, our break even point.
- If we want to quantify, we need to integrate: `integrate(function(p) dbeta(p, 14, 27), 0, 0.5)` -> 0.9807613 with absolute error < 5.9e-06
- Absolute error just because computers can't perfectly calculate integrals, usually leads to a very, negligible error.
- This result tells us that, given our evidence, there is 0.98 probability that the true probability of getting two coinds out of the black box is less than 0.5.

- We mostly never know true probabilities for events - that's why beta distribution is one of the most powerful tools for understanding our data.

# 6. Conditional Probability {#ch6}

- In this chapter learn how to reason about conditional probabilities - where probs are not independent.
- Also learn about Bayes' theorem.
- Guillane Barre Syndrome (GBS) as incidence of 2 in 100,000
- This can be increased if you get a flu vaccine so,
    - usually $P(GBS) = \frac{2}{100000}$ 
    - but $P(GBS) = \frac{3}{100000}$
- Conditional probabilities allow us to demonstrate how information changes our beliefs.
- Consider colour blindness - 4.25% of people are colour blind. Caused by defective gene in X chromosome.
- Males only have 1 X chromosome, so about 16 times more likely to be colour blind.
    - $P(\textrm{colour blind}) = 0.0425$
    - $P(\textrm{colour blind | female}) = 0.005$
    - $P(\textrm{colour blind | male }) = 0.08$
- Assume male/female are split 50-50
- $P(\textrm{male, colour bline}) = p(\textrm{male}) \times p(\textrm{colour blind} = 0.5 \times 0.0425 = 0.02125$... problem... clearer if we try product rule with females.
- $P(\textrm{female, colour bline}) = p(\textrm{female}) \times p(\textrm{colour blind} = 0.5 \times 0.0425 = 0.02125$
- Can't be right that the two probs are the same?!?!
- This is because we failed failed to account for dependence between gender and colour blindness!!!
- $P(\textrm{male, colour bline}) = p(\textrm{male}) \times p(\textrm{colour blind | male} = 0.5 \times 0.08 = 0.04$
- Thus, generalize the product rule: $P(A, B) = P(A) \times P(B|A)$
- Also, update the sum rule: $P(A \textrm{ or } B) = P(A) + P(B) - P(A) \times P(B|A)$
- How can we determine $P(\textrm{male | colour blind})$ ? Bayes'!
- THe heart of Bayesian statistics is data - and right now we have 1 piece of data: that the person we're interested in, is indeed colour blind.
- Let $N$ represent the total propulation of people. 
- We know the person is colour blind, so we restrict to poeple who are colour blind, thus, $P(\textrm{male | colour blind}) = \frac{\textrm{?}}{P(\textrm{colour blind} \times N)}$.
- For the numerator, we want to calculate people who are male <i> and </i> colour blind: $P(\textrm{male}) \times P(\textrm{colour blind | male}) \times N$
- So: $P(\textrm{male | colour blind}) = \frac{P(\textrm{male}) \times P(\textrm{colour blind | male}) \times N}{P(\textrm{colour blind} \times N)} = 0.941$ (the N's cancel)
- In general, Bayes': $P(A | B) = \frac{P(A)P(B|A)}{P(B)} = \frac{P(A \cap B)}{P(B)}$
- Think about it - the $P(B)$ goes in the denominator, because it's the part of the world we're restricting to. Like in the colour blind example, we only care about $P(\textrm{colour blind})$ because we <i>condition</i> on it!
- The key takeaway here is that Bayes' allows evidence to change the strength of our beliefs. Again, think of the colour blind example. We knew the person was colour blind. Before we knew that, we reckoned a 50% chance of them being male... but after we knew this info? 94.1% chance of them being male. Hot damn!











